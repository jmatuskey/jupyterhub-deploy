#! /bin/bash -eu

export PATH="`pwd`/tools":${PATH}

# ----------------- derived inputs, nominally don't change --------------
# automatically sourced into setup-env

# Octarine AWS JupyterHub setup
#export ACCOUNT=${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com
#export ECR_ACCOUNT=${CENTRAL_ECR_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com

if [ "$USE_CENTRAL_ECR" == "true" ]
then
    export ECR_REGISTRY=${CENTRAL_ECR_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com
    export IMAGE_REPO=${DEPLOYMENT_NAME}
    export ECR_ACCOUNT_TO_USE=${CENTRAL_ECR_ACCOUNT_ID}
else
    export ECR_REGISTRY=${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com
    export IMAGE_REPO=${DEPLOYMENT_NAME}-user-image
    export ECR_ACCOUNT_TO_USE=${ACCOUNT_ID}
fi

export JUPYTERHUB_DIR=`pwd`

export COMMON_REPO=${IMAGE_REPO}

export ADMIN_ARN=arn:aws:iam::${ACCOUNT_ID}:role/${ADMIN_ROLENAME}

export IMAGE_DIR=`pwd`/deployments/${DEPLOYMENT_NAME}/image
export CONFIG_DIR=`pwd`/deployments/${DEPLOYMENT_NAME}/config

export COMMON_IMAGE_DIR=`pwd`/deployments/common/image
export COMMON_CONFIG_DIR=`pwd`/deployments/common/config


if [[ "${PERSONAL_IMAGE}" == "0" ]]; then
    export COMMON_ID=${ECR_REGISTRY}/${COMMON_REPO}:${COMMON_TAG}
    export IMAGE_ID=${ECR_REGISTRY}/${IMAGE_REPO}:${IMAGE_TAG}
else
    export COMMON_ID=${COMMON_REPO}:${COMMON_TAG}
    export IMAGE_ID=${IMAGE_REPO}:${IMAGE_TAG}
fi

# -------------------------------------------------------------------
# When DOCKER_BUILDKIT is set Docker enables buildkit and "build" is
# effectively "buildx"; Setting the env var also works with older
# distributions which pre-date buildx.
#
# Buildkit has two killer features:
#   1. It can set up caches for package download directories which
#        persist between builds if they're not cleared.
#   2. It can set up multiple builders enabling parallel builds of
#        different missions and build parameters.  See image-build-all.
#

export DOCKER_BUILDKIT=1

#
# Set this to 1 to enable buildkit package cache overlays and to turn
# off our own cache clearing code.   Directories cached by buildkit
# are not included in the final image so cache clearing is not needed.
#

export USE_BUILDKIT_CACHING=0

export BUILDKIT_STEP_LOG_MAX_SIZE=10000000
export BUILDKIT_STEP_LOG_MAX_SPEED=10000000

# ---------------------------------------------------------------------------
#
# BUILDKIT is used to define options which prefix the command on RUN lines in
# Dockerfiles.   For now,  this is how we define Docker package caching.
#
# In a perfect world we'd just write this in Dockerfiles:
#
# RUN  ${BUILDKIT}  <command>
#
# but unfortunately Docker treats ${BUILDKIT} literally rather than expanding
# it as a modifier to the RUN statement.
#
# Consequently, in our framework Dockerfiles are first pre-processed into .x
# versions which either include or omit the buildkit switches defined below in
# the image-update script.  While not saved, the .x file is what is actually
# passed to docker build.  In theory, these caching options are a performance
# optimzation only.  If in doubt, set USE_BUILDKIT_CACHING=0.  Despite the
# complexity, at a minimum, BUILDKIT is really good at eliminating repeat
# downloads from PyPi; This makes it faster to iterate on the mission images
# when they're using env-compile and env-sync in particular, each of which does
# it's own package downloads when starting from an empty cache; so on an
# iteration, two downloads becomes zero downloads and saves G's of package
# retrieval.

if [[ "${USE_BUILDKIT_CACHING}" == "1" ]]; then
    export BUILDKIT="--mount=type=cache,sharing=private,target=/home/jovyan/.cache,uid=1000,gid=100"
    export BUILDKIT="${BUILDKIT} --mount=type=cache,sharing=private,target=/opt/conda-cache,uid=1000,gid=100"
    export BUILDKIT="${BUILDKIT} --mount=type=cache,sharing=private,target=/var/cache/apt,uid=1000,gid=100"
else
    export BUILDKIT=""
fi

# -----------------------------------------------------------------------------
# Among other things, don't clear the package caches during installs if this is
# set, regardless of the state of BUILDKIT.  In addition to increasing image
# sizes, not clearing the caches seems to aid key debug tools like pipdeptree.
# IMPORTANT:  this only works when USE_BUILDKIT_CACHING=0 because outside the
# scope of docker build,  the BUILDKIT cache overlays are not seen/used.  So
# running image-sh or image-dev to poke around will see empty package caches
# despite setting JH_DEVELOP=1.

export JH_DEVELOP=0

# ----------------------------------------------------------------------------
# PIP_SWITCHES are passed through to pip by Docker and the pip install scripts
# env-update and env-compile/sync.

export PIP_SWITCHES="--no-color --default-timeout 100"
if [[ "${USE_BUILDKIT_CACHING}" == "0" && "${JH_DEVELOP}" != "1" ]]; then
    export PIP_SWITCHES="${PIP_SWITCHES} --no-cache-dir"
fi
# Add debug switches here as needed.
# export PIP_SWITCHES="${PIP_SWITCHES} -vv"

# --------------- general setup ---------------------------------

export TMOUT=7200
export TF_LOG=TRACE
export TF_LOG_PATH=terraform.log

alias awsu="awsudo -d 3600 $ADMIN_ARN"
alias terraform-init="awsu terraform init -backend-config=./backend.conf -backend-config=./backend.conf"
alias terraform-apply="awsu terraform apply --var-file=${DEPLOYMENT_NAME}.tfvars"
alias terraform-destroy="awsu terraform destroy -var-file=${DEPLOYMENT_NAME}.tfvars"
alias helm-destroy="awsu helm uninstall ${DEPLOYMENT_NAME}-${ENVIRONMENT}"
alias where="echo ${DEPLOYMENT_NAME}-${ENVIRONMENT}-${USE_FROZEN}"
alias update-kubeconfig="awsu aws eks update-kubeconfig --name $DEPLOYMENT_NAME"
alias pods="kubectl get pods -A"

# where,  failing for GitHub Actions even with bash shell
